#!/usr/bin/env python3
'''Download ERA5 data for voyages.

Usage: download_era5 INPUT OUTPUT

Arguments:

  INPUT   Input track file (NetCDF).
  OUTPUT  Output directory.
'''

JOBS = 2

VARS_PLEV = [
	'fraction_of_cloud_cover',
	'geopotential',
	'specific_cloud_ice_water_content',
	'specific_cloud_liquid_water_content',
	'temperature',
]

VARS_SURF = [
	'geopotential',
	'surface_pressure',
	'sea_ice_cover',
	#'total_precipitation',
	'convective_rain_rate',
	'large_scale_rain_rate',
]

import sys
import os
import tempfile
from multiprocessing.pool import Pool
import cdsapi
import shutil
import numpy as np
import ds_format as ds
import aquarius_time as aq

def download_surf(year, month, day, lon1, lon2, lat1, lat2, out):
	c = cdsapi.Client()
	c.retrieve(
		'reanalysis-era5-single-levels',
		{
			'product_type': 'reanalysis',
			'format': 'netcdf',
			'variable': VARS_SURF,
			'time': [
				'00:00', '01:00', '02:00',
				'03:00', '04:00', '05:00',
				'06:00', '07:00', '08:00',
				'09:00', '10:00', '11:00',
				'12:00', '13:00', '14:00',
				'15:00', '16:00', '17:00',
				'18:00', '19:00', '20:00',
				'21:00', '22:00', '23:00',
			],
			'area': [lat2, lon1, lat1, lon2],
			'year': '%d' % year,
			'month': '%d' % month,
			'day': '%d' % day,
			'nocache': '43649254',
		},
		out,
	)

def download_plev(year, month, day, lon1, lon2, lat1, lat2, out):
	c = cdsapi.Client()
	c.retrieve(
		'reanalysis-era5-pressure-levels',
		{
			'product_type': 'reanalysis',
			'format': 'netcdf',
			'variable': VARS_PLEV,
			'pressure_level': [
				'1', '2', '3',
				'5', '7', '10',
				'20', '30', '50',
				'70', '100', '125',
				'150', '175', '200',
				'225', '250', '300',
				'350', '400', '450',
				'500', '550', '600',
				'650', '700', '750',
				'775', '800', '825',
				'850', '875', '900',
				'925', '950', '975',
				'1000',
			],
			'time': [
				'00:00', '01:00', '02:00',
				'03:00', '04:00', '05:00',
				'06:00', '07:00', '08:00',
				'09:00', '10:00', '11:00',
				'12:00', '13:00', '14:00',
				'15:00', '16:00', '17:00',
				'18:00', '19:00', '20:00',
				'21:00', '22:00', '23:00',
			],
			'area': [lat2, lon1, lat1, lon2],
			'year': '%d' % year,
			'month': '%d' % month,
			'day': '%d' % day,
			'nocache': '43649254',
		},
		out,
	)

DOWNLOAD_FUNC = {
	'surf': download_surf,
	'plev': download_plev,
}

if __name__ == '__main__':
	if len(sys.argv) != 3:
		sys.stderr.write(sys.modules[__name__].__doc__)
		sys.exit(1)
	input_ = sys.argv[1]
	output = sys.argv[2]

	d = ds.read(input_)

	start = d['time'][0]
	end = d['time'][-1]

	start = np.floor(start - 0.5) + 0.5
	end = np.floor(end - 0.5) + 0.5

	items = []
	for t in np.arange(start, end + 1):
		mask = (d['time'] >= t) & (d['time'] < t + 1)
		if np.sum(mask) == 0:
			continue
		lon = d['lon'][mask]
		lat = d['lat'][mask]
		lon1 = np.floor(np.min(lon))
		lon2 = np.ceil(np.max(lon))
		lat1 = np.floor(np.min(lat))
		lat2 = np.ceil(np.max(lat))
		items += [[t, lon1, lon2, lat1, lat2]]

	with tempfile.TemporaryDirectory() as tmpdir:
		def task(args):
			t, *args2 = args
			date = aq.to_date(t)
			year, month, day = date[1:4]
			name = '%04d-%02d-%02d.nc' % (year, month, day)
			for product in ['plev', 'surf']:
				try: os.mkdir(os.path.join(output, product))
				except FileExistsError: pass
				out = os.path.join(output, product, name)
				if os.path.exists(out):
					continue
				tmpfile = os.path.join(tmpdir, '%s_%s' % (product, name))
				func = DOWNLOAD_FUNC[product]
				print('download_' + product, year, month, day, *args2, tmpfile)
				func(year, month, day, *args2, tmpfile)
				print('shutil.move', tmpfile, out)
				shutil.move(tmpfile, out)

		with Pool(JOBS) as pool:
			pool.map(task, items)
